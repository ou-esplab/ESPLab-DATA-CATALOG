import os
import yaml
import xarray as xr
import pandas as pd
import cftime

base_dir = "/data/esplab/shared"
#categories = ["model", "obs", "reanalysis"]
categories = ["model"]

def get_netcdf_files(variable_dir):
    return sorted([os.path.join(variable_dir, f) for f in os.listdir(variable_dir) if f.endswith(".nc")])

def detect_frequency(ds):
    if "time" not in ds:
        return "unknown"
    try:
        dt = pd.to_timedelta(ds.time.diff("time").values[0])
        if dt.days == 1:
            return "daily"
        elif dt.seconds == 3600:
            return "hourly"
        elif dt.days >= 28:
            return "monthly"
    except Exception:
        pass
    return "unknown"

def extract_metadata(nc_files):
    if not nc_files:
        return {"long_name": "unknown", "units": "unknown", "date_range": "unknown", "n_files": 0, "frequency": "unknown"}

    try:
        ds = xr.open_dataset(nc_files[0], decode_times=True)
        var_name = list(ds.data_vars)[0] if ds.data_vars else "unknown"
        long_name = ds[var_name].attrs.get("long_name", var_name)
        units = ds[var_name].attrs.get("units", "unknown")
        freq = detect_frequency(ds)

        if "time" in ds.coords:
            times = ds.time.values
            try:
                if isinstance(times[0], cftime.DatetimeNoLeap):
                    start = pd.Timestamp(times[0].strftime("%Y-%m-%d"))
                    end = pd.Timestamp(times[-1].strftime("%Y-%m-%d"))
                else:
                    start = pd.to_datetime(times[0])
                    end = pd.to_datetime(times[-1])
                date_range = f"{start.date()} to {end.date()}"
            except Exception as e:
                print(f"‚ö†Ô∏è Failed decoding time: {e}")
                date_range = "unknown"
        else:
            date_range = "unknown"

        ds.close()
        return {
            "long_name": long_name,
            "units": units,
            "date_range": date_range,
            "n_files": len(nc_files),
            "frequency": freq
        }
    except Exception as e:
        print(f"‚ùå Failed to read metadata from {nc_files[0]}: {e}")
        return {
            "long_name": "unknown",
            "units": "unknown",
            "date_range": "unknown",
            "n_files": len(nc_files),
            "frequency": "unknown"
        }

def build_catalog_for_category(cat_path, cat_name):
    print(f"üìÅ Building catalog for: {cat_name}")
    catalog = {
        "metadata": {
            "title": f"{cat_name} NetCDF Catalog",
            "version": 1,
            "description": f"Autogenerated catalog for {cat_name}"
        },
        "sources": {}
    }

    for root, dirs, _ in os.walk(cat_path):
        for d in dirs:
            var_path = os.path.join(root, d)
            if not os.path.isdir(var_path):
                continue

            nc_files = get_netcdf_files(var_path)
            if not nc_files:
                continue

            meta = extract_metadata(nc_files)
            freq = meta.get("frequency", "unknown")
            key = os.path.relpath(var_path, cat_path)
            full_key = f"{cat_name}/{freq}/{key}"

            print(f"‚ûï Adding {full_key} ({meta['n_files']} files)")

            catalog["sources"][full_key] = {
                "description": f"{meta['long_name']} ({meta['units']}), {meta['date_range']}",
                "driver": "netcdf",
                "args": {
                    "urlpath": os.path.join(var_path, "*.nc"),
                    "consolidated": False,
                },
                "metadata": {
                    "long_name": meta["long_name"],
                    "units": meta["units"],
                    "date_range": meta["date_range"],
                    "n_files": meta["n_files"],
                    "frequency": freq,
                    "data_location": var_path
                }
            }

    return catalog

def write_catalog_yaml(catalog_dict, filename):
    with open(filename, "w") as f:
        yaml.dump(catalog_dict, f, sort_keys=False)
    print(f"‚úÖ Written catalog: {filename}")

if __name__ == "__main__":
    for category in categories:
        cat_dir = os.path.join(base_dir, category)
        if not os.path.exists(cat_dir):
            print(f"‚ö†Ô∏è Missing directory: {cat_dir}")
            continue
        catalog_dict = build_catalog_for_category(cat_dir, category)
        write_catalog_yaml(catalog_dict, f"{category}.yaml")
